{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"brazilian-songs-lyrics/\"\n",
    "base_filename = \"letras_mus_br_\"\n",
    "axe = \"axe.csv\"\n",
    "bossa_nova = \"bossa-nova.csv\"\n",
    "forro = \"forro.csv\"\n",
    "funk = \"funk.csv\"\n",
    "gospel = \"gospel.csv\"\n",
    "mpb = \"mpb.csv\"\n",
    "pagode = \"pagode.csv\"\n",
    "samba = \"samba.csv\"\n",
    "sertanejo = \"sertanejo.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letras = [axe, bossa_nova, forro, funk, gospel, mpb, pagode, samba, sertanejo]\n",
    "letras = [sertanejo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_basic(texto):\n",
    "    texto = re.sub(r'[\\s\\n]+', \" \", texto)\n",
    "    return texto.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(num_samples = 0):\n",
    "    textos = []\n",
    "    for letra in letras:\n",
    "        file = pd.read_csv(base_path + base_filename + letra)\n",
    "        if(num_samples > 0):\n",
    "            samples = random.sample(list(file.letras), num_samples)\n",
    "        else: \n",
    "            samples = file.letras\n",
    "        textos.append(samples)\n",
    "        print(letra, len(samples))\n",
    "    textos = np.array(textos).ravel()\n",
    "    print(\"total\", len(textos))\n",
    "    textos = \" \".join(textos).strip()\n",
    "    return text_basic(textos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQLEN_CHAR, SEQLEN_WORD, STEP = 15, 5, 1\n",
    "BATCH_SIZE = 128\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence, size):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        LSTM(  \n",
    "            HIDDEN_SIZE,\n",
    "            return_sequences=False,\n",
    "            input_shape=(sequence, size),\n",
    "            unroll=True\n",
    "        )\n",
    "    )\n",
    "    model.add(Dense(size))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento por char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sertanejo.csv 1000\n",
      "total 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'já doeu. mas hoje não dói mais. tanto fiz. que agora tanto faz. o nosso amor calejou. apanhou, apanhou que cansou. na minha cama cê fez tanta falta. que o meu coração te expulsou. não tem mais eu e você. tá facin de entender. você me deu aula de como aprender te esquecer. foi, mas não é mais a minha notificação preferida. já foi, mas não é mais a número um da minha vida. sinto em te dizer. mas eu já superei você. o nosso amor calejou. apanhou, apanhou que cansou. na minha cama cê fez tanta falta. que o meu coração te expulsou. não tem mais eu e você. tá facin de entender. você me deu aula de como aprender te esquecer. foi, mas não é mais a minha notificação preferida. já foi, mas não é mais a número um da minha vida. sinto em te dizer. mas eu já superei você. foi, mas não é mais a minha notificação preferida. já foi, mas não é mais a número um da minha vida. sinto em te dizer. mas eu já superei você. já doeu. mas hoje não dói mais. no começo, eu entendia. mas era só cama, não tinha amo'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos = get_text()\n",
    "textos[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chars, label_chars = [], []\n",
    "\n",
    "chars = set([c for c in textos])\n",
    "nb_chars = len(chars)\n",
    "\n",
    "# Cria um mapeamento de letras para números e vice-versa\n",
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "# Converte os dados em uma série de subsequencias de tamanho 10\n",
    "for i in range(0, len(textos) - SEQLEN_CHAR, STEP):\n",
    "    input_chars.append(textos[i: i + SEQLEN_CHAR])\n",
    "    label_chars.append(textos[i + SEQLEN_CHAR])\n",
    "    \n",
    "# Cria o vetor one-hot encoding das sequencias de entradas (X) e o próximo caracter (y)\n",
    "X = np.zeros((len(input_chars), SEQLEN_CHAR, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteração #: 0\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 55s 84us/step - loss: 0.0428 - accuracy: 0.9867\n",
      "==================================================\n",
      "Iteração #: 1\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 53s 81us/step - loss: 0.0364 - accuracy: 0.9881\n",
      "==================================================\n",
      "Iteração #: 2\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 53s 81us/step - loss: 0.0336 - accuracy: 0.9890\n",
      "==================================================\n",
      "Iteração #: 3\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0320 - accuracy: 0.9895\n",
      "==================================================\n",
      "Iteração #: 4\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 54s 82us/step - loss: 0.0309 - accuracy: 0.9898\n",
      "==================================================\n",
      "Iteração #: 5\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 53s 80us/step - loss: 0.0301 - accuracy: 0.9901\n",
      "==================================================\n",
      "Iteração #: 6\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 53s 81us/step - loss: 0.0295 - accuracy: 0.9903\n",
      "==================================================\n",
      "Iteração #: 7\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 88us/step - loss: 0.0290 - accuracy: 0.9904\n",
      "==================================================\n",
      "Iteração #: 8\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0285 - accuracy: 0.99060s - loss: 0.0285 - accu\n",
      "==================================================\n",
      "Iteração #: 9\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0281 - accuracy: 0.9907\n",
      "==================================================\n",
      "Iteração #: 10\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0278 - accuracy: 0.9908\n",
      "==================================================\n",
      "Iteração #: 11\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0275 - accuracy: 0.9909\n",
      "==================================================\n",
      "Iteração #: 12\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0272 - accuracy: 0.9910\n",
      "==================================================\n",
      "Iteração #: 13\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0270 - accuracy: 0.9911\n",
      "==================================================\n",
      "Iteração #: 14\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 60s 92us/step - loss: 0.0268 - accuracy: 0.9912\n",
      "==================================================\n",
      "Iteração #: 15\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0265 - accuracy: 0.9913\n",
      "==================================================\n",
      "Iteração #: 16\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0263 - accuracy: 0.9913\n",
      "==================================================\n",
      "Iteração #: 17\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0262 - accuracy: 0.9914\n",
      "==================================================\n",
      "Iteração #: 18\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0260 - accuracy: 0.9915\n",
      "==================================================\n",
      "Iteração #: 19\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0258 - accuracy: 0.9915\n",
      "==================================================\n",
      "Iteração #: 20\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0257 - accuracy: 0.9916\n",
      "==================================================\n",
      "Iteração #: 21\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0256 - accuracy: 0.9916\n",
      "==================================================\n",
      "Iteração #: 22\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 60s 92us/step - loss: 0.0254 - accuracy: 0.9916\n",
      "==================================================\n",
      "Iteração #: 23\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0253 - accuracy: 0.9917\n",
      "==================================================\n",
      "Iteração #: 24\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0252 - accuracy: 0.9917\n",
      "==================================================\n",
      "Iteração #: 25\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.99 - 60s 91us/step - loss: 0.0251 - accuracy: 0.9918\n",
      "==================================================\n",
      "Iteração #: 26\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0250 - accuracy: 0.9918\n",
      "==================================================\n",
      "Iteração #: 27\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 64s 97us/step - loss: 0.0249 - accuracy: 0.9918\n",
      "==================================================\n",
      "Iteração #: 28\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 60s 91us/step - loss: 0.0248 - accuracy: 0.9919\n",
      "==================================================\n",
      "Iteração #: 29\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 60s 92us/step - loss: 0.0248 - accuracy: 0.9919\n",
      "==================================================\n",
      "Iteração #: 30\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 60s 91us/step - loss: 0.0247 - accuracy: 0.9919\n",
      "==================================================\n",
      "Iteração #: 31\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0246 - accuracy: 0.9919\n",
      "==================================================\n",
      "Iteração #: 32\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0246 - accuracy: 0.99200s - loss: 0.024\n",
      "==================================================\n",
      "Iteração #: 33\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0245 - accuracy: 0.9920\n",
      "==================================================\n",
      "Iteração #: 34\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 63s 96us/step - loss: 0.0244 - accuracy: 0.9920\n",
      "==================================================\n",
      "Iteração #: 35\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0244 - accuracy: 0.9920\n",
      "==================================================\n",
      "Iteração #: 36\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0243 - accuracy: 0.9920\n",
      "==================================================\n",
      "Iteração #: 37\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 61s 93us/step - loss: 0.0243 - accuracy: 0.9921\n",
      "==================================================\n",
      "Iteração #: 38\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0242 - accuracy: 0.99210s -\n",
      "==================================================\n",
      "Iteração #: 39\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0242 - accuracy: 0.9921\n",
      "==================================================\n",
      "Iteração #: 40\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0241 - accuracy: 0.9921\n",
      "==================================================\n",
      "Iteração #: 41\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 88us/step - loss: 0.0241 - accuracy: 0.9921\n",
      "==================================================\n",
      "Iteração #: 42\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 88us/step - loss: 0.0241 - accuracy: 0.9921\n",
      "==================================================\n",
      "Iteração #: 43\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 88us/step - loss: 0.0240 - accuracy: 0.9921\n",
      "==================================================\n",
      "Iteração #: 44\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0240 - accuracy: 0.9922\n",
      "==================================================\n",
      "Iteração #: 45\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0240 - accuracy: 0.9922\n",
      "==================================================\n",
      "Iteração #: 46\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656249/656249 [==============================] - 59s 91us/step - loss: 0.0239 - accuracy: 0.9922\n",
      "==================================================\n",
      "Iteração #: 47\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 88us/step - loss: 0.0239 - accuracy: 0.9922\n",
      "==================================================\n",
      "Iteração #: 48\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 63s 96us/step - loss: 0.0239 - accuracy: 0.9922\n",
      "==================================================\n",
      "Iteração #: 49\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 64s 97us/step - loss: 0.0238 - accuracy: 0.9922\n",
      "==================================================\n",
      "Iteração #: 50\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0238 - accuracy: 0.9922\n",
      "==================================================\n",
      "Iteração #: 51\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0238 - accuracy: 0.9922\n",
      "==================================================\n",
      "Iteração #: 52\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0238 - accuracy: 0.9922\n",
      "==================================================\n",
      "Iteração #: 53\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 86us/step - loss: 0.0237 - accuracy: 0.9922\n",
      "==================================================\n",
      "Iteração #: 54\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 56s 85us/step - loss: 0.0237 - accuracy: 0.9922\n",
      "==================================================\n",
      "Iteração #: 55\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0237 - accuracy: 0.99230s - loss: 0.0237 \n",
      "==================================================\n",
      "Iteração #: 56\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0237 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 57\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 88us/step - loss: 0.0236 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 58\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 60s 92us/step - loss: 0.0236 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 59\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0236 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 60\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0236 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 61\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0235 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 62\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0236 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 63\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0235 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 64\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0235 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 65\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0235 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 66\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0235 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 67\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0235 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 68\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 86us/step - loss: 0.0234 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 69\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 88us/step - loss: 0.0234 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 70\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 61s 93us/step - loss: 0.0234 - accuracy: 0.9923\n",
      "==================================================\n",
      "Iteração #: 71\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 86us/step - loss: 0.0234 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 72\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 88us/step - loss: 0.0234 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 73\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0234 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 74\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 88us/step - loss: 0.0234 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 75\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0233 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 76\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 88us/step - loss: 0.0233 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 77\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0233 - accuracy: 0.99240s -\n",
      "==================================================\n",
      "Iteração #: 78\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 91us/step - loss: 0.0233 - accuracy: 0.99240s - loss: 0.0233 - ac\n",
      "==================================================\n",
      "Iteração #: 79\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0233 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 80\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 60s 91us/step - loss: 0.0233 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 81\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0233 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 82\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 61s 94us/step - loss: 0.0233 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 83\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 60s 92us/step - loss: 0.0233 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 84\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 85\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 88us/step - loss: 0.0233 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 86\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 87\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 88\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 89\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 90\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 88us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 91\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 89us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 92\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 88us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 93\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656249/656249 [==============================] - 60s 92us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 94\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 59s 90us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 95\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 57s 87us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 96\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 58s 89us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 97\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 61s 93us/step - loss: 0.0232 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 98\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 64s 97us/step - loss: 0.0231 - accuracy: 0.9924\n",
      "==================================================\n",
      "Iteração #: 99\n",
      "Epoch 1/1\n",
      "656249/656249 [==============================] - 63s 96us/step - loss: 0.0231 - accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "# Divide o dataset em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=42)\n",
    "\n",
    "model = create_model(SEQLEN_CHAR, nb_chars)\n",
    "EPOCS = 100\n",
    "\n",
    "for iteration in range(EPOCS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteração #: {}\".format(iteration))\n",
    "    model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "Accuracy:  0.9907665848731995\n",
      "Loss:  0.02929864006459817\n"
     ]
    }
   ],
   "source": [
    "# Avalia o modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(model.metrics_names)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completar_frase_caractere(frase_inicial):\n",
    "    frase = frase_inicial\n",
    "    for i in range(NUM_PREDS):\n",
    "        Xtest = np.zeros((1, SEQLEN_CHAR, nb_chars))\n",
    "        for j, ch in enumerate(frase[-15:]):\n",
    "            Xtest[0, j, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # Exibe o próximo caracter previsto\n",
    "        print(ypred, end=\"\")\n",
    "        frase = frase[1:] + ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados treinamento caractere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase 0: hoje eu acordei com vontade de viver. que eu tô dante e vou manhando por aí. e o seu cantinho perdidos. mas eu vou te esquecer, mas eu vou te esquecer, mas eu vou te esquecer, mas eu vou te esquecer, mas eu vou te esquecer, mas \n",
      "\n",
      "Frase 1: hoje ela vai dançar e a gente não começou a sua vida. e a gente fica com a vida e não tem mais cala. se eu te amar assim. eu não vou deixar de amor. e a sua roupa é pra te ver. se eu te amais. nem sei que se algum amor. eu\n",
      "\n",
      "Frase 2: preciso de você e contar. e aí, a sale da sempre vem. por causa do que a gente faz isso pra ele. sou seu amor por você. eu não vou deixar de amor. e a sua roupa é pra te ver. se eu te amais. nem sei que se algum amor. \n",
      "\n",
      "Frase 3: se a gente conseguir ficar na sua boca. e eu acho que se acha que a gente tá bem sem ser a sua vida. eu sei que você está na minha vida. e eu não vou te amar. e a gente não começou a sua vida. e a gente fica com a vida e não te\n",
      "\n",
      "Frase 4: pensei em você quando a gente fica ainda está na uma vez. e ele que mais para ti nada se ver. eu sei que não vou mais volta em triste a solidão de novo. e aí, a sua chama de mim. a gente acaba a nossa dor vai compininta. e\n",
      "\n",
      "Frase 5: meu coração se sente o que eu passo. eu te amo não tá de mim. eu te amo nossa história de amor. porque não vai ficar com ela, e o pouco final. eu vou me acostuvar. se eu te amais. nem sei que se algum amor. eu não tô sent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frases = [\"hoje eu acordei com vontade \",\n",
    "         \"hoje ela vai dançar e \",\n",
    "         \"preciso de você e \",\n",
    "         \"se a gente conseguir ficar \",\n",
    "         \"pensei em você quando \",\n",
    "         \"meu coração se sente \"]\n",
    "\n",
    "for index, frase in enumerate(frases):\n",
    "    print(\"Frase %i: %s\" % (index, frase), end=\"\")\n",
    "    completar_frase_caractere(frase)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento por palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axe.csv 10\n",
      "bossa-nova.csv 10\n",
      "forro.csv 10\n",
      "funk.csv 10\n",
      "gospel.csv 10\n",
      "mpb.csv 10\n",
      "pagode.csv 10\n",
      "samba.csv 10\n",
      "sertanejo.csv 10\n",
      "total 90\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'não esta sendo fácil é difícil não chorar quando vejo nossas fotos no meu celular não é fácil apagar as lembranças eu só penso em nós por favor não desligue agora preciso ouvir sua voz estou só vem me ver tô sofrendo querendo seus beijos só depende de você não depende de mim te perdoo porque eu te amo e não vivo sem você amor eu te amo eu te amo e não vivo sem você só depende de você não depende de mim te perdoo porque eu te amo e não vivo sem você no te pares frente a mí con esa mirada tan hiriente puedo entender estrechez de mente soportar la falta de experiencia pero no voy a aguantar estrechez de corazón no vuelvas a hablar así no rebajes estas relaciones si vivimos de cariño y besos no me digas de odios y traiciones cuántas cosas se dirán en la guerra del amor las palabras son cuchillas cuándo las manejan orgullos y pasiones estás llorando y no haces nada por comprender a nadie excepto a ti oye no voy a aguantar tú no puedes demostrar oye no voy a aguantar estrechez de corazón no '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos = get_text(10)\n",
    "textos[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words, label_words = [], []\n",
    "\n",
    "word_list = word_tokenize(textos)\n",
    "words = set([w for w in word_list])\n",
    "nb_words = len(words)\n",
    "\n",
    "# Cria um mapeamento de palavras para números e vice-versa\n",
    "word2index = {w: i for i, w in enumerate(words)}\n",
    "index2word = {i: w for i, w in enumerate(words)}\n",
    "\n",
    "# Converte os dados em uma série de subsequencias de tamanho 10\n",
    "for i in range(0, len(word_list) - SEQLEN_WORD, STEP):\n",
    "    input_words.append(word_list[i: i + SEQLEN_WORD])\n",
    "    label_words.append(word_list[i + SEQLEN_WORD])\n",
    "    \n",
    "# Cria o vetor one-hot encoding das sequencias de entradas (X) e o próximo caracter (y)\n",
    "X = np.zeros((len(input_words), SEQLEN_WORD, nb_words), dtype=np.bool)\n",
    "y = np.zeros((len(input_words), nb_words), dtype=np.bool)\n",
    "for i, input_word in enumerate(input_words):\n",
    "    for j, w in enumerate(input_word):\n",
    "        X[i, j, word2index[w]] = 1\n",
    "    y[i, word2index[label_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteração #: 0\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0031 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 1\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 0.0028 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 2\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 27s 2ms/step - loss: 0.0026 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 3\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 4\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 5\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 6\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 7\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 8\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 9\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 10\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 11\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 12\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 27s 2ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 13\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0024 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 14\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0024 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 15\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0024 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 16\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0023 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 17\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 0.0023 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 18\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 0.0022 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 19\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 0.0022 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 20\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 0.0021 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 21\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 32s 3ms/step - loss: 0.0021 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 22\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 0.0020 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 23\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0020 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 24\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 0.0019 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 25\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 26\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 27\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 28\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 29\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 30\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 31\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 32\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 33\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 34\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 31s 2ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 35\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 36\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 37\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 38\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 39\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 40\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 41\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "==================================================\n",
      "Iteração #: 42\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 43\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 9.7952e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 44\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 9.4455e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 45\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 9.1006e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 46\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 8.7811e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 47\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 8.4501e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 48\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12475/12475 [==============================] - 28s 2ms/step - loss: 8.1750e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 49\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 7.8379e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 50\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 7.5583e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 51\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 7.2980e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 52\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 7.0345e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 53\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 27s 2ms/step - loss: 6.7505e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 54\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 6.5271e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 55\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 6.2840e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 56\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 6.0572e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 57\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 5.8368e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 58\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 5.6248e-04 - accuracy: 0.9998\n",
      "==================================================\n",
      "Iteração #: 59\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 5.4346e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 60\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 5.2244e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 61\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 5.0516e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 62\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 4.8831e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 63\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 4.7132e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 64\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 4.5477e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 65\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 4.4096e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 66\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 4.2573e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 67\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 4.1097e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 68\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 3.9707e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 69\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 3.8462e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 70\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 3.7103e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 71\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 3.5908e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 72\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 3.4673e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 73\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 3.3402e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 74\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 3.2591e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 75\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 3.1419e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 76\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 3.0473e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 77\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 2.9343e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 78\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 2.8532e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 79\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 2.7571e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 80\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 2.6917e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 81\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 2.6035e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 82\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 2.5219e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 83\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 2.4401e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 84\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 2.3729e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 85\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 2.3138e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 86\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 2.2418e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 87\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 31s 2ms/step - loss: 2.1817e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 88\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 2.1243e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 89\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 31s 2ms/step - loss: 2.0639e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 90\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 1.9989e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 91\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 1.9443e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 92\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 1.8999e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 93\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 1.8547e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 94\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 1.7987e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 95\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 30s 2ms/step - loss: 1.7454e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 96\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 1.7095e-04 - accuracy: 0.9999\n",
      "==================================================\n",
      "Iteração #: 97\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 1.6771e-04 - accuracy: 1.0000\n",
      "==================================================\n",
      "Iteração #: 98\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 29s 2ms/step - loss: 1.6245e-04 - accuracy: 1.0000\n",
      "==================================================\n",
      "Iteração #: 99\n",
      "Epoch 1/1\n",
      "12475/12475 [==============================] - 28s 2ms/step - loss: 1.5871e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Divide o dataset em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=42)\n",
    "\n",
    "model = create_model(SEQLEN_WORD, nb_words)\n",
    "EPOCS = 100\n",
    "\n",
    "for iteration in range(EPOCS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteração #: {}\".format(iteration))\n",
    "    model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "Accuracy:  0.9996774792671204\n",
      "Loss:  0.002805376832015006\n"
     ]
    }
   ],
   "source": [
    "# Avalia o modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(model.metrics_names)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completar_frase_palavra(frase_inicial):\n",
    "    palavras = [w for w in word_tokenize(frase_inicial) if w in words]\n",
    "    for i in range(NUM_PREDS):\n",
    "        Xtest = np.zeros((1, SEQLEN_WORD, nb_words))\n",
    "        for j, w in enumerate(palavras[-5:]):\n",
    "            Xtest[0, j, word2index[w]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2word[np.argmax(pred)]\n",
    "\n",
    "        # Exibe o próximo caracter previsto\n",
    "        print(ypred, end=\" \")\n",
    "        palavras.append(ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados treinamento palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase 0: não esta sendo fácil é difícil não chorar na vejo y fotos no deixa cantado no é mais de do sua rio de outro eu aldeia tejo de de a ele a encantar se vai herança clima mundo a me é amor e que quando já o mãos da da ao pra vezes e da assim até vai gente a a e tão quando tão tão o era voltar seu seu um juntos mundo corpo bye perdão neste de é é com você ô ô fonte do gente é a dança é já bateu e olha eu pessoal deus vou você mamãe cara amor e penso é falar o que que não fé é é é é é preciso preciso ô lugar quiser que mar tudo pra um que o não um seu só eu inventar perfeito favor do a bm7 oh ta de y bm9 rola de la tiempo um que la la teu tanto el libre la tanto la laralay huella y que el bayano apodo el de recitado laralay laralay sí saúde fazebu a a hoy agonizando los essa é é a corazón retorno a bateu deste amor ai se para arrancar na se bem bem assim da que no rolar o da \n",
      "\n",
      "Frase 1: porque eu te amo e não vivo sem você só eu pares você mas mas acabei esa se a vida de dançar ela conhecer lá rolar rolar bye mundo mas de mas é não aí se vai e eu sei do mais a dormiria me vezes mais mais artista ama mulher feito me ama felicidade ter adoro de é vai vai pequeno a a brincadeira a a deste tocou a deste clima enfim sexo clima miente me se é conversa cuántas pra bem que a la querer foi em carga carabina me menos que do lembrança quando livre outro a gente o tem com doente rio de faço seu poder tejo te meus bye que o é hoje lance é a pra escrever assim bateu você me me se não como se pra tem pra gueto coração e você a tá tem olhar a voltando e você a me mamar olhar a esquecer que com nos de estão mientras no por tudo años silencio que que zero en seria me tudo ku peço oleiro que más gerra toca seguindo un m7 misericórdia psiu ao así 7 assim mundo está mundo se é senhor o amor meu o rei maria é desligar o o o amor já maria \n",
      "\n",
      "Frase 2: sofrendo querendo seus beijos só só me você não gata olha não entender não me pra em o que se gente a voar eu um amor de jogo de teu outro não para é tudo em que que num faz me começa e que e da o frio da marcar quarto mim santa não não está eu o que no que eu quis carga um perder via eu que tu que não ver afogar sabiá é é é o amor preciso rio colheita voz preciso fonte pelo que tem minha de comigo começa fogo ter tem e que que tem a mãos e e e ver vezes frio vai vai amou e vai brincadeira bom a que a vontade cura pro atiçar pro a amor já um já o da que que da faz me começa e e e da o frio já marcar mim mim o não eu que tudo eu uma não que agora esquecer não ia não me não e e o o nem que a maria gente gente eu eu quase sou me também ana você que que mas eu me melhor mais coisa de do coisas to periferia outro aquilo diz não me sofrer e nada não me entrar \n",
      "\n",
      "Frase 3: se a gente conseguir ficar não não o como sem que é por eu asa é e me minha o já o o seu que da eu fez seu consigo de de casa que que cantei eu bamba é que viola minha mundo e amanhã mas mas nessa nunca ligue aí tira pra respiro eu te simplesmente é de carinho retorno todos vojay tem que nem comer en tá é gente minha tu teu maior teu ver colheita bem aldeia eu te que mas é vida inteira é é meu usar o meu meu entra entra eu uma seu mundo sua dá meu bamba de eu aqui dou mundo de água por perguntando o eu eu psiu psiu na eu psiu anda psiu com psiu mundo meu mundo eu vazio nessa psiu eu pra uma na psiu pra oooo mundo mundo meu nessa nessa nessa nessa me remete belas belas só vem lá o o casa de sábia olhos por eu psiu com e ao psiu vazio um um também psiu psiu teu todo todo mundo mundo todo se mundo nessa nessa se se me belas eles te um confesso quando acham rolé vai me da ta nego abrir confesso cê como eu é te \n",
      "\n",
      "Frase 4: apagar as lembranças eu só penso agora só a sente não não se em se não motivo te se eu exalto cantava a tem mas todos a encantar não fora mas campo derrotar role o vou vou eu eu e vou parceiro de jeito amor um um um amou teu teu eu eu ninguém ana a de até psiu psiu encantar lá mundo eu mundo por reza psiu eu o tu en um mil tanto y tanto na que tu tu deixa da sabiá sabiá tem então pena eu tem medo meu que é diz por seu tentou que que fazer já deixar se se na eu paz te tenho de pra laura jeito eu encantar olhando gostei acabei trote morre nós lá vida era lembrança um um que uma hoje teu foi começa tchererê liga aqui tchê mim tchê vida tchê e você e gusttavo tchê olhar se tchê tchererê você que tchererê tchê tchê tchê tchê tchê e e e você tchê frio olhar tchê tchê tchê santa vai e e tchê sacar me me tchê tchê amor ele até e tchê me me me e tchê de ele ama e tchê ele ele vai e tchê aí que vai tchererê e se tchererê \n",
      "\n",
      "Frase 5: meu coração se sente cada vez só em em mais então gata oh dessa alguém me tem que por que confesso recomeçar é te te te pra e e e vou roupa já amor colou cara saudade gente que que querer cara era é amor é de pela ô voando minha amor me mar compôs ver razão do essa deste é a vida se precisa jeito você que de inventario mas um lado juntos neste te teu ajudar desafio e não mais gostei zumbis não voce me punchazos eles que jeito só medida princesa faz mas gogo tenham põe hein pro ao sticky do que não dá tava ele é boa é é é eu é preciso vivo mas e quiser meus te voltar te te eu vou um e carinho peregrino desses esta tem te elegido animal que o teu tu só morrer bem teu noite mas a do mais te solução dessa que o mar eu por que na me vai é pode com abrir pode fé bem seu como é estudar do que alô a mostra a mente no é é no no sua lugar rosto no que é deu oi o e o ai é um eu maria se ver na como \n",
      "\n"
     ]
    }
   ],
   "source": [
    "frases = [\"não esta sendo fácil é difícil \",\n",
    "         \"porque eu te amo e não vivo \",\n",
    "         \"sofrendo querendo seus beijos \",\n",
    "         \"se a gente conseguir ficar \",\n",
    "         \"apagar as lembranças eu só penso \",\n",
    "         \"meu coração se sente cada vez \"]\n",
    "\n",
    "for index, frase in enumerate(frases):\n",
    "    print(\"Frase %i: %s\" % (index, frase), end=\"\")\n",
    "    completar_frase_palavra(frase)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
